{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39010b2a-67b8-4745-95c6-633831136bee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 1: Install TensorFlow and other required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "359e66c5-a809-4458-8a32-f0d0a748b9c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0b0e3b2-3977-4931-9087-a35e426e5384",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96a9ddd0-04f5-4d7c-a629-647d4aca2a0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 2: Load your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "252a425b-9aee-4a31-84a0-b08b257c4955",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ceab4d1-25c3-48c9-92dd-d1a0eef4d499",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "type(mnist.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df85b203-6b65-4958-b659-4fdd37407245",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print('Dataset type:', type(mnist.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01115f8a-c137-47e7-9873-84e6e041215e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mnist.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8ec05a2-2c86-4f87-8214-74e040ad87cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 3: Convert the DataFrame into TensorFlow Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20fa3d2d-5fa0-40e5-b446-7057ff55878b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(mnist):\n",
    "    # Load MNIST dataset\n",
    "    # mnist = fetch_openml('mnist_784')\n",
    "\n",
    "    # Convert the data and target into numpy arrays\n",
    "    X = mnist.data.astype('float32')\n",
    "    y = mnist.target.astype('int32')\n",
    "\n",
    "    # Normalize the data to have values between 0 and 1\n",
    "    X /= 255.0\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Reshape the training data to 28x28x1 images\n",
    "    X_train = X_train.values.reshape((-1, 28, 28, 1))\n",
    "    X_test = X_test.values.reshape((-1, 28, 28, 1))\n",
    "\n",
    "    # Create TensorFlow Dataset objects for training and testing sets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "    # Print the shape of the training and testing sets\n",
    "    print('Training data shape:', X_train.shape)\n",
    "    print('Training labels shape:', y_train.shape)\n",
    "    print('Testing data shape:', X_test.shape)\n",
    "    print('Testing labels shape:', y_test.shape)\n",
    "\n",
    "    return X_test, y_test, X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29e957ee-64c8-4d4e-9a2a-40a160e25e54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test, y_test, X_train, y_train = get_dataset(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bca1afda-1c8e-4227-b9ea-7ec65fe89fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 4: Define a deep learning mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f825bcb-9beb-436c-8772-d6b75ef9df18",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Option 1: Define a deep learning model from scratches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76ccbd70-035f-4419-a53b-9e261036a6f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4199a880-c15b-45d4-bf12-d0e4837a4209",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Option 2: Define a deep learning model from a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ea30576-8e9e-46f5-9dd3-b8f4178d5e65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Resize the input images to 224x224 and convert them to RGB with three channels\n",
    "X_train = tf.image.grayscale_to_rgb(tf.image.resize(X_train, [224, 224]))\n",
    "X_test = tf.image.grayscale_to_rgb(tf.image.resize(X_test, [224, 224]))\n",
    "\n",
    "print('Training data shape:', X_train.shape)\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Testing data shape:', X_test.shape)\n",
    "print('Testing labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cc5b338-5f1e-40da-b01f-53915476f5bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the MobileNet model, excluding the top layer\n",
    "base_model = MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add a global average pooling layer and a fully connected output layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the new layers to create the full model\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c52fa08-54b5-47e9-b00a-f0c003a0135e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 5: Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e18d849-f43f-4766-b376-63b8ef8d1c43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54f7fb46-0ab2-4718-bfb1-35d0cdb09be5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 6: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d68855d9-952a-4483-bfb5-9358fa2a67bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, batch_size=560, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2ff4f7e-87d3-434f-a823-9cf688f4c478",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 7: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "639f149f-78c0-4b47-af48-c73ccee9e820",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test loss: ', test_loss)\n",
    "print('Test Acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e002fd6-d86c-4ef8-956c-46490ba5e427",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 8: Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36d1b272-2f25-46a9-8e76-f69989270f0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cf5de89-0c1b-479d-bbac-8511ce4abafd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.reshape(X_test[1].shape, (1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7871d76-3b98-49f2-86fa-dec48dc09a97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "# Make predictions on new data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c614f1d9-7e5b-4ea4-87ec-46dc5018bf20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.reshape(X_test[1], (1, 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e9ce554-a9b4-4bc5-be03-86242b1332a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48dffe65-1ded-4e35-a28c-9225d56ae0e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63d25ed5-ac1b-4487-9cff-d8bec71563ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_test_array = y_test.values\n",
    "# Get the label for the first example in the test set\n",
    "label = y_test_array[0]\n",
    "\n",
    "# Print the label\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561b0c84-eb64-48fc-8f2d-3f59e4d8bc52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def predict_and_compare(model, X_test, y_test, index):\n",
    "    # Get the example from X_test at the given index\n",
    "    example = X_test[index]\n",
    "\n",
    "    # Reshape the example to the expected input shape\n",
    "    example = np.reshape(example, (1, 28, 28, 1))\n",
    "\n",
    "    # Predict the label for the example\n",
    "    y_pred = model.predict(example)\n",
    "\n",
    "    # Convert the predicted probabilities to class label\n",
    "    y_pred_label = np.argmax(y_pred, axis=1)[0]\n",
    "\n",
    "    # Get the true label from y_test using the index\n",
    "    y_test_array = y_test.values\n",
    "    # Get the label for the first example in the test set \n",
    "    y_true = y_test_array[index]\n",
    "\n",
    "    # Print the predicted and true labels\n",
    "    print(\"Predicted label:\", y_pred_label)\n",
    "    print(\"True label:\", y_true)\n",
    "    \n",
    "    # Return the predicted and true labels\n",
    "    return y_pred_label, y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30505fe6-2abe-4678-8d88-76b5c5d104ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict and compare the label for the first example in the test set\n",
    "y_pred_label, y_true = predict_and_compare(model, X_test, y_test, 0)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Deep Learning model implementation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
